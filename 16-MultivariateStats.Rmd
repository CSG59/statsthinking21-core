---
output:
  pdf_document: default
  bookdown::gitbook:
    lib_dir: "book_assets"
    includes:
      in_header: google_analytics.html
  html_document: default
---

# Multivariate statistics {#multivariate}

```{r setup, echo=FALSE}

library(tidyverse)
theme_set(theme_minimal())
```

The term *multivariate* refers to analyses that involve more than one variable. This might be a bit confusing as a chapter title, since we have already encountered a number of analyses in the book that involve more than one variable.  However, in general we were always trying to relate a single outcome variable (or *dependent variable*) to one or more explanatory (or *independent*) variables.  When we speak of "multivariate statistics" we are generally referring to analyses that attempt to understand the relationship between a large set of variables that could include both independent and dependent variables.

There are many different kinds of multivariate analysis, but we will focus on three of the major approaches in this chapter.  First, we may simply want to understand and visualize the structure that exists in the data, by which we usually mean which variables or observations are related to which other.  We would usually define "related" in terms of some measure that indexes the distance between the values across variables.  One important method that fits under this category is known as *clustering*, which aims to find clusters of observations that are similar across variables.

Second, we may want to take a large number of variables and reduce them to a smaller number of variables in a way that retains as much information as possible.  This is referred to as *dimensionality reduction*, where "dimensionality" refers to the number of variables in the dataset.  

Third, we might want to model the data in a way that estimates many different relationships at once.  A commonly used approach in the social sciences and psychology is known as *structural equation modeling*, which allows one to specify and test a wide range of models regarding the relationships between sets of variables.  An important aspect of these models is that they can include *latent variables*, which are variables that we can't observe directly but that we think exist (such as personality characteristics such as "openness to experience" or "grit") and can be manifested in our measurements (such as responses to items on a personality test).  A specific version of this method known as *factor analysis* is commonly used in psychology to understand how the behavior observed on a set of psychological tests relates to a set of latent variables.

Before we start this chapter, it's important to point out that a deep understanding of multivariate statistics requires one to understand some basics of linear algebra.  We will try to explain the concepts in a way that avoids too much math, but will include some boxes that go a bit deeper into the necessary aspects of linear algebra.

## What are multivariate data?

As an example of multivariate analysis, we will look at a dataset collected by Eisenberg et al. [@Eisenberg:2019um].  This study was interested in understanding  how many different aspects of cognitive function are related to one another, and one of the areas of interest was *working memory*, which refers to the ability to hold information in mind and transform it.  The study included several different measures that are thought to relate to the amount of information that an individual can hold in their working memory, which is known as their *capacity*:

- There were four different tasks that require an individual to retain information and then repeat it. These tasks either used spatial locations or numeric digits as their stimuli. For each of those stimulus types, one task required the subject to repeat the stimuli in the order that they were experienced (a *forward span* task), and one required them to repeat the stimuli in the reverse order (a *reverse span* task).  For each of these, the dependent variable was the number of items that the subject could accurately repeat.
- One additional task, known as an *N-back* task, required subjects to watch a stream of stimuli and report for each stimulus whether it matched the stimulus that occurred some number (N) of stimuli back in the stream.  The task adaptively changed the number back based on the subject's performance, and the dependent variable was the mean N for each subject.

Another area examined in this study was risk taking, using a survey called the Domain-Specific Risk Taking Scale (or DOSPERT).  One section of this survey asks subjects to rate their degree of risk taking in several different domains, including: ethical, financial, health/safety, recreational, and social.



After these scores have been computed for each of the 522 participants in Eisenberg's study, we end up with 5 numbers for each individual.  While multivariate data can some times have thousands or even millions of variables, the methods that we can apply to understand the structure of the data are quite similar.

```{r DataPrep, echo=FALSE, message=FALSE}

behavdata <- read_csv('data/Eisenberg/meaningful_variables.csv',
                      show_col_types = FALSE) 
demoghealthdata <- read_csv('data/Eisenberg/demographic_health.csv',
                            show_col_types = FALSE) 

# recode Sex variable from 0/1 to Male/Female
demoghealthdata <- demoghealthdata %>%
  mutate(Sex = recode_factor(Sex, `0`="Male", `1`="Female"))

# combine the data into a single data frame by subcode
alldata <- merge(behavdata, demoghealthdata, by='subcode')

rename_list = list('upps_impulsivity_survey' = 'UPPS', 'sensation_seeking_survey' = 'SSS',
                   'dickman_survey' = 'Dickman',  'bis11_survey' = 'BIS11', 
                   'spatial_span' = 'spatial', 'digit_span' = 'digit',
                   'adaptive_n_back' = 'nback', 'dospert_rt_survey' = 'dospert',
                   'motor_selective_stop_signal.SSRT' = 'SSRT_motorsel',
                   'stim_selective_stop_signal.SSRT' = 'SSRT_stimsel',
                   'stop_signal.SSRT_low' = 'SSRT_low',
                   'stop_signal.SSRT_high' = 'SSRT_high')
                   
impulsivity_variables = c('Sex')

keep_variables <- c("spatial.forward_span", "spatial.reverse_span", "digit.forward_span","digit.reverse_span", "nback.mean_load")

for (potential_match in names(alldata)){
  for (n in names(rename_list)){
    if (str_detect(potential_match, n)){
      # print(sprintf('found match: %s %s', n, potential_match))
      replacement_name <- str_replace(potential_match, n, toString(rename_list[n]))
      names(alldata)[names(alldata) == potential_match] <- replacement_name
      impulsivity_variables <- c(impulsivity_variables, replacement_name)
    }
  }
}

impulsivity_data <- alldata[,impulsivity_variables] %>%
  drop_na()


wm_dospert_data <- alldata[, keep_variables] %>%
    drop_na()

tipsdata = alldata[,grep('ten_item', names(behavdata))]


ssrtdata = alldata[,c('subcode', names(alldata)[grep('SSRT_', names(alldata))])] %>% drop_na() %>% select(-stop_signal.proactive_SSRT_speeding)
upps_data <- alldata %>%
  select(starts_with('UPPS'), 'subcode') %>%
  setNames(gsub("UPPS.", "", names(.)))

impdata <- inner_join(ssrtdata, upps_data) %>% drop_na() %>% select(-subcode) %>% scale()
```


## Visualizing multivariate data

The fundamental problem with multivariate data is that the human eye and brain simply are not equipped to visualize data with more than two or three dimensions.  There are various tools that we can use to try to visualize multivariate data, but all of them break down as the number of variables grows. Once the number of variables becomes too large to directly visualize, one approach is to first reduce the number of dimensions (as discussed below), and then visualize that reduced dataset.

### Matrix of pairwise plots



```{r}
#library(psych)
#pairs.panels(impulsivity_data)

library(gpairs)

gpairs(impdata)
#library(GGally)

#ggpairs(upps_data)
```

```{r}
library(psych)
pairs.panels(impdata)
```

### Heatmap

In some cases we wish to visualize the relationships between a large number of variables at once.


```{r, fig.width=16, fig.height=8}

gc <- ggcorr(impdata %>% select(-Sex), , hjust = 1) + 
  theme(plot.margin = margin(2, 2, 2, 4, "cm"),)
gc$layout$clip[gc$layout$name == "panel"] <- "off"
grid::grid.draw(gc)

```

```{r fig.width=12, fig.height=7}
library(gplots)
cc = cor(impdata)
par(mai=c(3, 1, 1, 3)+0.1) 
heatmap.2(cc, trace='none', dendrogram='none', 
          cellnote=round(cc, 2), notecol='black', key=FALSE,
          margins=c(12,8), srtCol=45, symm=TRUE, revC=TRUE, notecex=3, 
          cexRow=3, cexCol=3, offsetRow=-120)

```

### Representing additional dimensions using different plotting features

```{r}

ggplot(as.data.frame(impdata), aes(y=positive_urgency, x=negative_urgency,  size=sensation_seeking)) + 
  geom_point(alpha=0.5) + 
  geom_smooth(method='lm')
```


## Clustering

```{r}
d <- dist(t(impdata))
hc <- hclust(d, method='ward')

library(ggdendro)

#convert cluster object to use with ggplot
dendr <- dendro_data(hc, type="rectangle") 

# TODO: https://stackoverflow.com/questions/21474388/colorize-clusters-in-dendogram-with-ggplot2

#your own labels (now rownames) are supplied in geom_text() and label=label
ggplot() + 
  geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + 
  geom_text(data=label(dendr), aes(x=x, y=y,label=dendr$labels$label, hjust=0), size=3) +
  coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + 
  theme(axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank()) + 
   geom_hline(yintercept=40, color='blue') + 
   geom_hline(yintercept=40, color='red') + 

   ylim(50, -10)

```

This shows us that the data from the three different tasks each cluster together.  
### Simple example: clustering countries by latitude/longitude


```{r}
countries <- read_delim('data/countries/country_data.csv') %>%
  # filter out countries with less than 1M population
  filter(Population2020 > 50000000)

dim(countries)
```

get region data from https://github.com/country-regions/country-region-data
population data from https://data.worldbank.org/indicator/SP.POP.TOTL


```{r}
ggplot(countries, aes(longitude, latitude, size=Population2020)) + geom_point()
```

```{r}
latlongdata <- countries %>%
  select(longitude, latitude)

d <- dist(latlongdata)
hc <- hclust(d, method='average')
```

```{r }
library(ggdendro)

#convert cluster object to use with ggplot
dendr <- dendro_data(hc, type="rectangle") 

# TODO: https://stackoverflow.com/questions/21474388/colorize-clusters-in-dendogram-with-ggplot2

#your own labels (now rownames) are supplied in geom_text() and label=label
ggplot() + 
  geom_segment(data=segment(dendr), aes(x=x, y=y, xend=xend, yend=yend)) + 
  geom_text(data=label(dendr), aes(x=x, y=y, label=countries$CountryCode[hc$order], hjust=0), size=3) +
  coord_flip() + scale_y_reverse(expand=c(0.2, 0)) + 
  theme(axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank()) + 
   geom_hline(yintercept=100, color='blue')

```

```{r}
cutree(hc, h=100)

```

## Dimensionality reduction

### Principal component analysis








## Structural equation modeling



### Factor analysis
